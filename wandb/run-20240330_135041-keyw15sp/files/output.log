INFO:train logger:Running trainer on cuda
/home/m4xig1/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
INFO:train logger:
⣿⣿⣿⣿⣿⣿⣿⣤⡘⡍⠛⠿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠿⠛⠋⡡⠊⠉⢀⠞⡻⠊⡐⠇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⣿⣿⡟⢿⠻⡀⠀⠀⠉⠛⠿⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⠟⠉⠀⠀⣠⠞⠃⠀⢀⡀⠀⠀⠈⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⣿⣿⡄⠀⢀⠳⡀⠀⠀⠀⠀⠀⠈⠙⢿⣿⣿⡿⠟⣻⠟⠉⠀⠀⠀⠀⠀⠀⠠⠟⠁⠀⠀⠀⣠⡞⠀⠀⡀⠠⢜⣡⠀⠀⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⣿⣿⡇⠂⣰⣧⠐⡄⠀⠀⠀⠀⠀⣐⣮⣤⠤⠀⠨⠴⣶⡶⡶⠤⣀⠀⠀⠀⠀⠀⠀⠑⠲⣿⣋⣭⣛⠁⠠⠒⢵⣏⡀⠀⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⣿⣿⣹⣄⢘⣧⠀⢺⣆⠀⣠⠴⠛⠉⡱⠁⠀⠀⠀⠀⠀⠀⠀⠑⠢⡹⣦⡀⠀⠀⠀⠀⠀⠈⠻⡗⠀⠀⣀⣀⣒⡓⠧⡀⠀⢠⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⣿⣿⣿⡈⣙⡿⠂⢈⡿⠋⠀⠀⠀⠈⠀⠀⠀⠀⠀⡀⠀⠀⠀⠀⠀⠀⠙⢝⣆⠑⡄⠀⠀⠀⠀⠘⢶⣀⣈⠉⣻⢿⡧⠀⠀⣸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣶⣿⣀⠞⠀⠀⡀⠀⠠⠂⠀⠀⠀⠀⠀⠱⠀⠀⠠⠀⠀⠀⠀⠀⠻⡱⣼⡄⠀⠀⠀⠀⠈⢗⠤⣅⣴⣟⣇⣠⠀⡏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣟⡿⠁⠀⠀⡰⠀⠀⡆⢰⠀⠀⠀⠀⠀⠀⢇⠀⠀⠑⡀⠀⠀⠀⠠⡘⢜⢿⡄⠀⢀⠀⠀⠈⢇⢨⣿⣿⠃⢀⣴⡅⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⣿⣿⣿⣿⠏⠀⠀⠀⢠⢃⠀⣰⠀⠘⠀⠀⠀⠀⣇⠀⢸⣧⡀⠀⠘⢦⠀⠠⠀⠉⢌⠺⣷⠀⠈⡆⠀⠀⠘⣿⢟⡿⢶⣿⡟⠘⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⣿⣿⡿⠃⠀⠀⠀⠀⣤⠇⢠⡟⡆⠀⡄⠀⠀⠀⠘⡄⠀⢏⠓⢄⠀⠣⠳⣄⠑⢄⠀⠣⡹⣇⠀⢰⠀⠀⠀⢳⠈⣰⣿⣿⢅⠘⣱⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⣿⠏⢠⠃⠀⠀⠀⢠⡟⠀⡾⠀⡇⠀⠂⠀⠀⠀⢳⠸⡄⠘⣄⣧⡦⡔⠒⠘⢯⡙⢍⠒⠚⢾⡀⠐⡆⠀⢡⠸⡮⠿⢫⡇⠘⡄⠀⢣⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⣿⣿⠟⠁⢠⠃⠀⠀⠀⠀⢸⠇⣸⠇⢠⢡⢀⢸⡀⠀⠀⠸⣧⢳⡠⢻⠀⠑⢜⣆⠘⠄⠑⢌⡳⡀⠀⠇⠀⣧⠀⢸⠀⣇⡰⠋⠀⠀⣷⠀⡀⠡⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⠟⠁⢀⣴⡏⠀⡄⠀⠀⠀⢸⢀⣿⡀⠤⢼⡞⡄⣷⡘⣆⠀⠹⣍⣷⡀⢣⠀⠀⣙⣻⣦⣤⣤⣭⣛⣲⣤⠀⢹⠀⠀⠀⣍⣠⣤⠁⡰⢿⠀⠰⡀⠱⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠋⢀⣠⣴⣿⣿⠁⠀⠁⠀⣸⠀⣾⠜⡏⠀⠀⠈⢿⡰⡘⣷⠘⣧⡀⠻⣿⣧⣀⣶⡿⢿⣿⣿⣿⣿⣿⡝⠻⣿⡶⠏⠀⠀⠀⢹⣿⣁⠜⡀⡿⣧⠀⡙⡄⠈⡢⡀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⡟⠀⠀⠀⠀⢿⠀⣿⠀⠃⠀⢀⣀⣨⠷⡑⢼⣧⡽⣷⣄⡀⢻⡠⡏⠀⠸⠏⢹⣿⣿⠙⡇⠀⣼⡇⠀⠀⠀⡆⣎⡙⢇⡰⢁⡇⣿⣧⣿⢮⠢⡀⠀⠑⠢⡀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⡇⠀⠀⡇⠀⢸⡇⢻⠀⢐⣾⠟⣿⣿⣿⣗⠀⠈⠻⣆⠝⠣⢄⠈⠀⠀⠀⠰⣟⠹⢻⣿⠁⠀⠃⠁⠀⠀⢸⡇⣃⡁⢸⠁⣼⢧⢸⠙⡟⢷⣕⡌⠒⠤⣀⠀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⡇⢸⠀⣧⠀⠸⣷⠘⣄⣾⠇⠀⠿⠛⣿⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣈⣁⠉⣁⣀⣀⢀⡁⠀⠀⢸⡄⡏⣡⢟⣿⣿⠸⠀⠄⠸⠀⠀⠀⠉⠀⠀⠀⠀⠀⠀⠀
⣿⣿⢻⣿⣿⡇⢸⡆⢹⡄⠀⢹⣧⣻⡻⣇⠀⠀⢰⣿⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣰⠟⢁⠠⠀⢸⠇⠀⠀⠸⠃⡗⣡⣾⡏⢿⠀⡇⡇⠀⠑⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⣸⣿⣿⡇⢸⣷⡘⣷⡀⠈⣿⣿⣧⠈⠂⠀⠀⠉⠀⠀⢀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠁⠀⠀⠀⠀⣾⠀⠀⠀⣀⠀⣿⣿⢿⡇⢸⡄⠀⢩⠀⠀⠀⠁⠀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⢸⣿⣿⣿⠘⣿⣷⣹⣷⣄⠘⣎⢻⣇⠀⠔⢫⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡔⢸⠀⠀⠀⣿⢠⣿⡇⢸⡇⠀⢷⠀⠸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⣿⣇⢿⣿⣿⣿⣿⡿⣏⠙⢿⠘⠒⠋⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠊⢀⣼⠀⡄⢠⡏⢸⣿⣧⠘⣿⠀⠈⣇⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⣿⣿⣾⣿⣿⣿⡿⢁⣿⠀⠸⣇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣴⠟⣿⠀⠁⢸⡁⣼⣿⣿⠀⡟⡇⠀⠼⡀⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣵⣿⢟⡄⠀⢛⠢⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣤⣾⠟⠁⢀⡏⠸⠀⣇⡆⣿⣿⣿⣇⣧⣿⡤⣶⣷⣸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⢸⣇⠀⠸⡀⢸⡏⠓⣦⣤⣀⣀⠀⠀⠀⠀⠀⣀⣤⣾⣿⠟⠁⣠⠐⠁⠃⡆⢠⣾⢱⣿⡏⢉⣀⣠⣴⢤⣤⣬⣁⡒⠢⠤⣄⣀⡀⠀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡏⣼⣿⠀⠀⠃⠘⡇⢀⣿⢸⣿⣿⣿⣿⣷⣶⣿⣿⣿⠟⠁⡠⠊⠀⠀⠀⣷⠁⢸⣟⣸⠿⠿⢧⡅⢱⣧⠀⡅⡇⠇⢳⠈⠁⠢⡀⠁⠀⠀⠀⠀⠀
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⢃⣿⢸⡇⠀⠰⠀⣿⢸⣿⣿⣿⣿⣿⠟⢛⣩⣿⡏⠁⠔⠈⢀⣠⠄⠒⢸⡟⠀⣿⡇⡇⠀⠀⢸⠃⠘⣿⠀⡁⢁⢸⠈⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀
⢹⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠏⣼⣿⢸⣿⡀⠀⠀⢸⣿⣿⣿⡿⠋⠵⡽⠿⠛⠛⠋⠉⠉⠉⠁⡁⠀⠀⣿⡇⢠⣿⣹⠁⠀⠀⣿⠀⢰⢿⠀⠙⠘⢸⡀⣷⠀⠀⠀⠀⠀⠀⠀⠀⠌
INFO:train logger:Train mode
train:   0%|                                                                                                                                    | 0/2684 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/m4xig1/speaker_extraction_SpEx/test.py", line 46, in <module>
    main()
  File "/home/m4xig1/speaker_extraction_SpEx/test.py", line 39, in main
    trainer.train(train_loader)
  File "/home/m4xig1/speaker_extraction_SpEx/trainer/base.py", line 178, in train
    batch = self.compute_loss(batch)
  File "/home/m4xig1/speaker_extraction_SpEx/trainer/trainer.py", line 36, in compute_loss
    elem_loss = self.loss(pred, batch["target"], batch["speaker_id"], is_train)
  File "/home/m4xig1/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/m4xig1/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/m4xig1/speaker_extraction_SpEx/loss/loss.py", line 84, in forward
    ce_loss = torch.nn.functional.cross_entropy(pred["logits"], speaker_id)
  File "/home/m4xig1/.local/lib/python3.10/site-packages/torch/nn/functional.py", line 3059, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: size mismatch (got input: [251], target: [4])
Traceback (most recent call last):
  File "/home/m4xig1/speaker_extraction_SpEx/test.py", line 46, in <module>
    main()
  File "/home/m4xig1/speaker_extraction_SpEx/test.py", line 39, in main
    trainer.train(train_loader)
  File "/home/m4xig1/speaker_extraction_SpEx/trainer/base.py", line 178, in train
    batch = self.compute_loss(batch)
  File "/home/m4xig1/speaker_extraction_SpEx/trainer/trainer.py", line 36, in compute_loss
    elem_loss = self.loss(pred, batch["target"], batch["speaker_id"], is_train)
  File "/home/m4xig1/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/m4xig1/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/m4xig1/speaker_extraction_SpEx/loss/loss.py", line 84, in forward
    ce_loss = torch.nn.functional.cross_entropy(pred["logits"], speaker_id)
  File "/home/m4xig1/.local/lib/python3.10/site-packages/torch/nn/functional.py", line 3059, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: size mismatch (got input: [251], target: [4])
tensor([-1.8150e-03,  4.2261e-02, -1.9196e-02, -3.0242e-02,  1.1477e-02,
         2.2181e-02,  1.0648e-02, -5.0969e-02,  6.1540e-02,  4.0747e-02,
        -1.4872e-02,  1.6921e-02, -2.4059e-02,  1.0372e-02, -6.9316e-04,
         2.8159e-02,  3.8234e-02,  1.2857e-02, -2.5872e-03, -3.6532e-02,
        -1.6968e-02,  1.3462e-02, -3.7585e-02, -3.5449e-02, -5.0613e-03,
         3.6005e-02, -1.0544e-02, -3.1592e-02,  3.5829e-02,  3.5748e-02,
         4.4949e-03,  2.7361e-02, -3.5183e-02,  9.4987e-03, -1.9273e-02,
         7.1031e-03,  4.4120e-02,  1.3231e-02,  2.0046e-02,  3.0425e-02,
        -1.1087e-02,  2.3694e-03, -3.5011e-02,  3.1062e-03, -3.2807e-02,
         9.6357e-03,  9.1901e-03,  4.8348e-02,  3.3898e-02,  1.4997e-02,
         9.2634e-04, -5.2018e-02,  4.2556e-02,  4.8325e-02,  1.5164e-02,
         3.3856e-02,  3.1003e-03,  1.7811e-02, -3.3195e-02,  1.6189e-03,
        -1.8939e-02, -1.9955e-02,  3.2901e-02,  2.8086e-02,  3.7144e-02,
         6.8623e-03, -9.7826e-03, -4.1515e-03, -2.5504e-04, -1.4890e-03,
         2.0696e-02, -1.0306e-02,  1.4197e-02,  5.6295e-02,  2.7451e-02,
        -2.7032e-02, -4.7442e-02, -2.0472e-02, -1.7104e-02, -2.5754e-02,
         4.2399e-02,  4.8123e-03,  2.4439e-02,  3.7517e-02, -5.9607e-04,
        -2.4170e-03,  5.0756e-02, -4.3607e-02,  1.7781e-02,  1.7845e-02,
         4.0073e-03, -6.0333e-02,  1.8464e-03, -7.3631e-03,  1.2395e-02,
         5.6009e-03,  1.3181e-02,  3.4962e-03,  1.4301e-02, -2.0557e-02,
         6.5807e-02, -1.8014e-02,  4.3332e-03,  9.3280e-03, -4.8505e-03,
         4.8767e-02,  7.8974e-03, -1.8784e-02,  5.7269e-03, -3.0270e-02,
         4.6251e-02, -7.9802e-03, -3.9577e-02, -3.3070e-02, -2.7579e-02,
        -3.4006e-02,  6.1354e-03,  1.1680e-02,  1.1144e-02, -2.2845e-03,
        -9.7090e-03,  5.3709e-02, -7.9780e-02,  4.3219e-02, -1.8354e-02,
         6.0463e-05,  2.1276e-02,  2.1799e-02, -1.7084e-02, -1.0917e-02,
        -2.9830e-02, -1.6550e-02, -1.4725e-02,  1.3456e-02, -1.3393e-02,
         3.3482e-02,  1.4209e-02, -5.1979e-04, -3.0795e-02,  1.1515e-02,
        -1.6073e-02, -3.3566e-03, -1.0170e-02, -2.2031e-02,  4.4315e-02,
        -1.5827e-02, -2.6632e-03,  6.1958e-03, -4.3701e-03,  3.2627e-03,
         3.5338e-03,  3.1537e-02,  6.2947e-02, -5.5030e-02,  3.3297e-02,
        -2.8215e-02,  3.1600e-02, -1.1047e-02,  1.7260e-02, -6.8344e-02,
         6.8748e-02,  3.3920e-02,  3.7426e-02,  4.9722e-02,  6.6750e-03,
         4.4250e-02,  3.6587e-02,  1.9669e-02,  2.7128e-02,  2.3750e-02,
        -3.7248e-03, -2.3460e-02,  1.8311e-02, -2.8951e-03, -1.7539e-03,
        -3.1738e-02,  1.7425e-05, -3.8559e-02,  3.0140e-02, -2.8958e-03,
         5.4450e-02, -1.7778e-02,  2.5034e-02, -4.8951e-02,  1.7933e-02,
         6.2863e-02, -1.6669e-03,  2.4999e-02, -2.1318e-02,  1.6688e-02,
        -9.5264e-03,  7.0921e-03, -3.7693e-03, -1.7676e-02, -2.7373e-02,
         1.6116e-02,  3.4577e-02,  3.1368e-02, -3.6428e-02, -1.7649e-02,
        -6.6942e-03,  7.8319e-03, -1.8452e-02,  2.8339e-02, -2.5482e-03,
        -5.7102e-02, -1.5347e-02, -5.7389e-03, -2.8270e-02,  1.5668e-02,
        -5.1274e-02,  2.1222e-02, -1.5541e-02,  1.1168e-02,  2.6203e-02,
        -7.5381e-03,  5.3663e-02,  4.3802e-02,  2.5100e-03,  2.6309e-02,
         1.8991e-02, -1.9436e-02,  3.5797e-02, -1.8762e-03, -4.8498e-03,
        -8.8408e-03, -2.0258e-03, -6.4480e-03,  6.5663e-03, -4.6728e-02,
        -4.9095e-02, -1.8041e-02,  1.0098e-02,  4.1367e-02,  8.1939e-03,
        -5.5184e-03, -3.3945e-02,  1.0430e-02,  9.0140e-03, -2.0925e-02,
         1.6721e-02,  3.1205e-02, -2.3480e-02, -2.4626e-02, -2.4223e-02,
         4.4571e-02,  2.3257e-02, -2.7182e-02,  3.8566e-02,  4.5322e-02,
        -1.9472e-02], device='cuda:0', grad_fn=<ViewBackward0>) tensor([131, 102,  66,  43], device='cuda:0')